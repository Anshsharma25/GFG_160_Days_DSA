{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c338e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob   NaN  60000.0\n",
      "2  Charlie  30.0      NaN\n",
      "3    David   NaN  80000.0\n",
      "4      Eva  45.0      NaN\n",
      "Mean Age: 33.333333333333336\n",
      "Median Salary: 60000.0\n",
      "      Name        Age   Salary\n",
      "0    Alice  25.000000  50000.0\n",
      "1      Bob  33.333333  60000.0\n",
      "2  Charlie  30.000000  60000.0\n",
      "3    David  33.333333  80000.0\n",
      "4      Eva  45.000000  60000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20948\\686281111.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(mean, inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20948\\686281111.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(medain, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, np.nan, 30, np.nan, 45],\n",
    "    'Salary': [50000, 60000, np.nan, 80000, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "mean = df['Age'].mean()\n",
    "print(f\"Mean Age: {mean}\")\n",
    "df['Age'].fillna(mean, inplace=True)\n",
    "                        \n",
    "\n",
    "\n",
    "medain = df['Salary'].median()\n",
    "print(f\"Median Salary: {medain}\") \n",
    "df['Salary'].fillna(medain, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c837db6",
   "metadata": {},
   "source": [
    "Label Encoding: Best for ordinal data or when the machine learning algorithm can handle integer-encoded categories without misinterpretation.â€‹\n",
    "\n",
    "One-Hot Encoding: Ideal for nominal data to prevent the model from assuming any ordinal relationship between categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b233d27",
   "metadata": {},
   "source": [
    "ðŸ”¢ Label Encoding with LabelEncoder\n",
    "Label Encoding transforms categorical labels into integer values. This is particularly useful for encoding target variables or ordinal features.â€‹\n",
    "scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c701ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: [2 1 0 1 2]\n",
      "Classes: ['blue' 'green' 'red']\n",
      "Original Labels: ['red' 'green' 'blue' 'green' 'red']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "labels = ['red', 'green', 'blue', 'green', 'red']\n",
    "\n",
    "# Initialize the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "\n",
    "print(\"Encoded Labels:\", encoded_labels)\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "# To inverse transform\n",
    "original_labels = le.inverse_transform(encoded_labels)\n",
    "print(\"Original Labels:\", original_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e7e44",
   "metadata": {},
   "source": [
    "One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ed956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Features:\n",
      " [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Categories: [array(['blue', 'green', 'red'], dtype='<U5')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "features = np.array([['red'], ['green'], ['blue'], ['green'], ['red']])\n",
    "\n",
    "# Initialize the encoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the features\n",
    "encoded_features = ohe.fit_transform(features)\n",
    "\n",
    "print(\"Encoded Features:\\n\", encoded_features)\n",
    "print(\"Categories:\", ohe.categories_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf9143",
   "metadata": {},
   "source": [
    "âœ… Label Encoding\n",
    "When to Use:\n",
    "\n",
    "Ordinal Data: Use Label Encoding when the categorical variable has a natural order or ranking. For example, educational levels like 'High School', 'Bachelor', 'Master', 'PhD' have a clear hierarchy.â€‹\n",
    "\n",
    "Target Variables: Label Encoding is often used for target variables in classification tasks, especially when the categories are ordinal.â€‹\n",
    "\n",
    "Why Use:\n",
    "\n",
    "Memory Efficiency: Label Encoding is more memory-efficient as it assigns a unique integer to each category without increasing the dimensionality of the dataset.â€‹\n",
    "\n",
    "Model Compatibility: Some algorithms, like decision trees and random forests, can handle label-encoded data effectively without misinterpreting the numeric relationships between categories.â€‹\n",
    "\n",
    "âœ… One-Hot Encoding\n",
    "When to Use:\n",
    "\n",
    "Nominal Data: Use One-Hot Encoding when the categorical variable does not have any intrinsic order. For example, colors like 'Red', 'Green', 'Blue' are nominal and should be one-hot encoded.â€‹\n",
    "\n",
    "Linear Models and Neural Networks: These models often perform better with one-hot encoded data, especially when the categorical variable has no inherent order.â€‹\n",
    "\n",
    "Why Use:\n",
    "\n",
    "Avoiding Implicit Ordering: One-Hot Encoding prevents the model from assuming any ordinal relationship between categories, which could lead to incorrect interpretations.â€‹\n",
    "\n",
    "Model Performance: For algorithms that assume numerical relationships between features, One-Hot Encoding ensures that each category is treated equally, improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af9ca3",
   "metadata": {},
   "source": [
    "## Normalization vs Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d89ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Normalized Data (MinMaxScaler):\n",
      "    Feature1  Feature2\n",
      "0      0.00      0.00\n",
      "1      0.25      0.25\n",
      "2      0.50      0.50\n",
      "3      0.75      0.75\n",
      "4      1.00      1.00\n",
      "\n",
      "ðŸ”¹ Standardized Data (StandardScaler):\n",
      "    Feature1  Feature2\n",
      "0 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107\n",
      "2  0.000000  0.000000\n",
      "3  0.707107  0.707107\n",
      "4  1.414214  1.414214\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Sample Data\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': [10, 20, 30, 40, 50],\n",
    "    'Feature2': [100, 200, 300, 400, 500]\n",
    "})\n",
    "minmax_scaler = MinMaxScaler()\n",
    "noramalize_data = minmax_scaler.fit_transform(data)\n",
    "noramalize_data = minmax_scaler.fit_transform(data)\n",
    "normalized_df = pd.DataFrame(noramalize_data , columns=data.columns)\n",
    "print(\"ðŸ”¹ Normalized Data (MinMaxScaler):\\n\", normalized_df)\n",
    "\n",
    "\n",
    "# StandardScaler: Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "standardized_data = standard_scaler.fit_transform(data)\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=data.columns)\n",
    "print(\"\\nðŸ”¹ Standardized Data (StandardScaler):\\n\", standardized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5066212",
   "metadata": {},
   "source": [
    "Detect and remove outliers using IQR and Z-score methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188b2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    values\n",
      "0       10\n",
      "1       12\n",
      "2       14\n",
      "3       15\n",
      "4       13\n",
      "5       16\n",
      "6       12\n",
      "7       11\n",
      "8      150\n",
      "9       14\n",
      "10      13\n",
      "11      10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'values': [10, 12, 14, 15, 13, 16, 12, 11, 150, 14, 13, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f28f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['values'].quantile(0.25)\n",
    "Q3 = df['values'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a2ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    values\n",
      "0       10\n",
      "1       12\n",
      "2       14\n",
      "3       15\n",
      "4       13\n",
      "5       16\n",
      "6       12\n",
      "7       11\n",
      "9       14\n",
      "10      13\n",
      "11      10\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define lower and upper bounds\n",
    "lowerbound = Q1 - 1.5 * IQR\n",
    "upperbound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Step 3: Filter out the outliers\n",
    "df_iqr_filter = df[(df['values']>= lowerbound)& (df['values'] <= upperbound)]\n",
    "\n",
    "# print(\"IQR Outliers Removed:\")\n",
    "print(df_iqr_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a600e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score Outliers Removed:\n",
      "    values\n",
      "0       10\n",
      "1       12\n",
      "2       14\n",
      "3       15\n",
      "4       13\n",
      "5       16\n",
      "6       12\n",
      "7       11\n",
      "9       14\n",
      "10      13\n",
      "11      10\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Calculate Z-scores\n",
    "z_scores = np.abs(stats.zscore(df['values']))\n",
    "\n",
    "# Step 2: Define a threshold (commonly 3)\n",
    "threshold = 2\n",
    "\n",
    "# Step 3: Filter out values with Z-score > threshold\n",
    "df_z_filtered = df[(z_scores < threshold)]\n",
    "\n",
    "print(\"Z-score Outliers Removed:\")\n",
    "print(df_z_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e450ce8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1d3057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age  Salary\n",
      "0    Male   23   50000\n",
      "1  Female   25   60000\n",
      "2  Female   31   75000\n",
      "3    Male   22   52000\n",
      "4  Female   29   68000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Age': [23, 25, 31, 22, 29],\n",
    "    'Salary': [50000, 60000, 75000, 52000, 68000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4bdc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age        Salary\n",
      "Gender                         \n",
      "Female  28.333333  67666.666667\n",
      "Male    22.500000  51000.000000\n"
     ]
    }
   ],
   "source": [
    "mean_df = df.groupby('Gender').mean(numeric_only=True)\n",
    "print(mean_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e50537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Age   Salary\n",
      "Gender               \n",
      "Female  29.0  68000.0\n",
      "Male    22.5  51000.0\n"
     ]
    }
   ],
   "source": [
    "median_df = df.groupby('Gender').median(numeric_only=True)\n",
    "print(median_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df767a0",
   "metadata": {},
   "source": [
    "## Write code to impute missing values using KNN imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b6ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing values:\n",
      "     age   salary  experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  27.0  54000.0         3.0\n",
      "2   NaN  58000.0         4.0\n",
      "3  35.0      NaN         5.0\n",
      "4  40.0  62000.0         NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Sample data banayi hai jisme kuch values missing hain\n",
    "data = {\n",
    "    'age': [25, 27, np.nan, 35, 40],\n",
    "    'salary': [50000, 54000, 58000, np.nan, 62000],\n",
    "    'experience': [2, 3, 4, 5, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame with missing values:\\n\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edac96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "#ðŸ‘‰ n_neighbors=2 ka matlab: jab koi value missing milegi, to usko bharne ke liye 2 sabse similar rows dekhi jaayengi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7805194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after KNN Imputation:\n",
      "     age   salary  experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  27.0  54000.0         3.0\n",
      "2  31.0  58000.0         4.0\n",
      "3  35.0  60000.0         5.0\n",
      "4  40.0  62000.0         4.5\n"
     ]
    }
   ],
   "source": [
    "dfimput = imputer.fit_transform(df)\n",
    "dfimput = pd.DataFrame(dfimput,columns=df.columns)\n",
    "print(\"\\nDataFrame after KNN Imputation:\\n\", dfimput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
